{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will again apply what you've learned in the lecture. This model is for a classifier and will use the standard MNIST handwritten zip code dataset. Run each of the cells to create the classifier model, train the model, and test the model to see how well the model performs. \n",
    "\n",
    "You can modify parameters in certain cells to change the way that the training is performed and see what happens. Experiment to see if you can get better results than the defaults. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ktnng\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "cell finished\n"
     ]
    }
   ],
   "source": [
    "# cell 1\n",
    "# notebook version 1.2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "print ('cell finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resetting the default graph is a good safety measure to make sure you are starting from a clean slate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell finished\n"
     ]
    }
   ],
   "source": [
    "# cell 2\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "print ('cell finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture we discussed the MNIST data set and the specialized python code created for this example to read the data set into appropriate variables. The read_data_sets function will download the raw data set, convert it into python data types, and store the information in the mnist variable. Once this is done we can examine the data set and use it to train, validate, and test our model. \n",
    "\n",
    "This cell downloads MNIST data into directory specified if it doesn't already exist and imports the MNIST dataset into variable mnist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-6b31137d56f1>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ktnng\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\ktnng\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ktnng\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ktnng\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ktnng\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "cell finished\n"
     ]
    }
   ],
   "source": [
    "# cell 3\n",
    "\n",
    "mnist = input_data.read_data_sets('/tmp/data', one_hot=True)\n",
    "\n",
    "print ('cell finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is meant to help understand the details of the MNIST dataset. You will notice a number of print statements that will print out different aspects of MNIST. Uncomment these and run the cell to see the results. \n",
    "\n",
    "The first print statement (2 lines) will print out the sizes of the train, validation, and test sets. \n",
    "\n",
    "The second shows how the labels are formatted as one hot arrays so that the labels match with the output of the neurons. You can change the index used to pick a particular image to see different labels. \n",
    "\n",
    "The next print statement uses the argmax function to return the index of the highest value in the label array. \n",
    "\n",
    "The next print statement prints out the number of pixels for an image in the training data. \n",
    "\n",
    "The final two statements plot the image from the index. Again feel free to modify the indices to see different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, validation, test: 55000, 5000, 10000\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "3\n",
      "784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Label: 3')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2339fd41748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cell 4\n",
    "\n",
    "# Run this cell to understand the format of the dataset. Uncomment the print commands one by one to understand what\n",
    "# the data set looks like. As you uncomment a line use shift-enter to run the cell once more. In the first print you\n",
    "# actually have to uncomment two lines or you will get an error. \n",
    "\n",
    "# 1. There are 55k, 5k, and 10k examples in train, validation, and test.\n",
    "print ('Train, validation, test: %d, %d, %d' % \n",
    "      (len(mnist.train.images), len(mnist.validation.images), len(mnist.test.images)))\n",
    "\n",
    "# 2. The format of the labels is 'one-hot'. Labels match with output of neurons.\n",
    "# The fifth image happens to be a '1'.\n",
    "# This is represented as '[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]'\n",
    "print (mnist.train.labels[11])\n",
    "\n",
    "# You can find the index of the label, like this:\n",
    "print (np.argmax(mnist.train.labels[11]))\n",
    "\n",
    "# 3. An image is a 'flattened' array of 28*28 = 784 pixels.\n",
    "print (len(mnist.train.images[11]))\n",
    "\n",
    "# 4. To display an image, first reshape it to 28x28.\n",
    "pylab.imshow(mnist.train.images[11].reshape((28,28)), cmap=pylab.cm.gray_r)   \n",
    "pylab.title('Label: %d' % np.argmax(mnist.train.labels[11])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell declares a number of constants we will use during the training process. There are 10 image classes, each image is 28 x 28 pixels. \n",
    "\n",
    "The default values for training are shown. Feel free to experiment to see how they change results, but don't change the number of classes or pixels or the model won't work anymore. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell finished\n"
     ]
    }
   ],
   "source": [
    "# cell 5\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "NUM_PIXELS = 28 * 28\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 0.5\n",
    "EPOCHS = 2000\n",
    "\n",
    "print ('cell finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This model will use two placeholders to feed information into the model. The `x` placeholder will accept the training or testing images so that they can be fed into the rest of the network. \n",
    "\n",
    "The `y_` placeholder accepts the expected network output value. It's value is compared to the generated value from the network and the loss calculated. \n",
    "\n",
    "Variable `w` is the trainable variable used to hold the weights per pixel and `b` is the bias. These values will be updated through the training process so that the model learns how to classify the digits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell finished\n"
     ]
    }
   ],
   "source": [
    "# cell 6\n",
    "\n",
    "# Define input variables\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None,NUM_PIXELS])\n",
    "# Accepts training/testing images\n",
    "y_ = tf.placeholder(tf.float32, [None, NUM_CLASSES])\n",
    "# Accepts the expected network output value. Compared to generated value from network and loss calculated\n",
    "\n",
    "w = tf.Variable(tf.truncated_normal([NUM_PIXELS,NUM_CLASSES], stddev=0.1))\n",
    "# Weights per pixel\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "# Bias\n",
    "# Weights and bias are updated throughout the training process to help the model learn\n",
    "\n",
    "print ('cell finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell specifies the matrix multiplication operation that does the inference step in the training process. The current values of `w` and `b` are used to predict the classification of the pixels input through the `x` placeholder. The output `y` is the current inferred output value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell finished\n"
     ]
    }
   ],
   "source": [
    "# cell 7\n",
    "\n",
    "y = tf.matmul(x,w) + b\n",
    "\n",
    "print ('cell finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to compare the calculated output value in `y` against the expected output passed in through the `y_` placeholder. This is done with the `tf.nn.softmax_cross_entropy_with_logits` function as discussed in the lecture. The value from this function is computed per training example. The mean of all loss values for a batch is gathered in variable `cross_entropy`. This loss value is used passed to an optimizer that will train the model based on the specified LEARNING_RATE. \n",
    "\n",
    "Since the optimizer understands the model graph, the trainable weights and biases are updated according to the loss values as training proceeds. The variable `train_step` actually specifies an operation that updates the weights and biases in accordance with the loss value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-28-7bd26ad3870b>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "cell finished\n"
     ]
    }
   ],
   "source": [
    "# cell 8\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "# Finds the mean of loss values for one batch\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "# Specifies an operation that updates weights and biases in accordance with the loss value\n",
    "\n",
    "print ('cell finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of training the model occurs in a session. Sessions can be created on the local machine or remote machines, thus the need to initialize variables before data is fed into the model for training or inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell finished\n"
     ]
    }
   ],
   "source": [
    "# cell 9\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "print ('cell finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the model out before it is trained to see how well it does. Since the weights and biases are random values there is a chance (about 1 in 10) that the correct value is returned from classification. This code will allow you to try an example to see if it works. \n",
    "\n",
    "The `image_index` variable is used to grab an example from the testing data. The expected label is captured in variable `exp_label`. The pixel data is captured in `x_image`. These values are fed to the network and the session run to predict the output in variable `outval`. Variable `label` is then calculated from the argmax of the outval. \n",
    "\n",
    "The results are printed out and the image plotted so you can see which one it is. \n",
    "\n",
    "Experiment with the `image_index` variable to see if you can find images where the untrained model correctly predicts the label. You will need to change the index and rerun this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated label = 7 expected label = 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Label: 7')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x233a1c18390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cell 10\n",
    "\n",
    "image_index = 80\n",
    "exp_label = np.argmax(mnist.test.labels[image_index], 0)\n",
    "x_image = np.reshape(mnist.test.images[image_index], [-1,784])\n",
    "\n",
    "outval = sess.run(y, feed_dict={x:x_image})\n",
    "label= np.argmax(outval[0],0)\n",
    "\n",
    "print (\"calculated label = {} expected label = {}\".format(label, exp_label))\n",
    "pylab.imshow(mnist.test.images[image_index].reshape((28,28)), cmap=pylab.cm.gray_r)   \n",
    "pylab.title('Label: %d' % np.argmax(mnist.test.labels[image_index])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell is where all the magic happens. The training data is applied to the model and the `train_step` is repeatedly run to adjust the trainable variables `w` and `b`. \n",
    "\n",
    "Notice that the training process is using the `next_batch` method of the dataset input code to retrieve batches of training data that are then applied to the model. \n",
    "\n",
    "Every 100 training steps the step and current loss values are output. The loss can be used to gauge the success of the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_step = 0 loss = 2.6818978786468506\n",
      "train_step = 100 loss = 0.33554136753082275\n",
      "train_step = 200 loss = 0.25595197081565857\n",
      "train_step = 300 loss = 0.2848292291164398\n",
      "train_step = 400 loss = 0.3364478051662445\n",
      "train_step = 500 loss = 0.3536141514778137\n",
      "train_step = 600 loss = 0.24208836257457733\n",
      "train_step = 700 loss = 0.3684713840484619\n",
      "train_step = 800 loss = 0.2541218400001526\n",
      "train_step = 900 loss = 0.39833882451057434\n",
      "train_step = 1000 loss = 0.3820236623287201\n",
      "train_step = 1100 loss = 0.182321697473526\n",
      "train_step = 1200 loss = 0.30529728531837463\n",
      "train_step = 1300 loss = 0.2944149672985077\n",
      "train_step = 1400 loss = 0.21205317974090576\n",
      "train_step = 1500 loss = 0.2824811637401581\n",
      "train_step = 1600 loss = 0.25405314564704895\n",
      "train_step = 1700 loss = 0.2688947021961212\n",
      "train_step = 1800 loss = 0.26403558254241943\n",
      "train_step = 1900 loss = 0.11974512040615082\n",
      "cell finished\n"
     ]
    }
   ],
   "source": [
    "# cell 11\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  loss, _ = sess.run([cross_entropy,train_step], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "  if t%100 == 0:\n",
    "    print('train_step = {} loss = {}'.format(t,loss))\n",
    "\n",
    "print ('cell finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained it is time to see how well it does the classification. A correct classification is one where the predicted label is the same as the expected label. Remember the label is specified by the index of the argument that has the highest value in the output vector from the neurons. The argmax function will return this value. \n",
    "\n",
    "If this value is compared to the expected output value, the two should match for a correct prediction. \n",
    "\n",
    "Variable `correct_prediction` is a vector of boolean values for the entire batch. Variable `accuracy` converts the boolean values to float32 values and calculates the mean. More true values gives a higher mean, or a higher accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9211636\n"
     ]
    }
   ],
   "source": [
    "# cell 12\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={x:mnist.train.images, y_:mnist.train.labels}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The previous cell showed the training accuracy because it used the training images. To get the testing accuracy let's run the accuracy on the test images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9205\n"
     ]
    }
   ],
   "source": [
    "# cell 13\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={x:mnist.test.images, y_:mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing accuracy is slightly different, but remember we did not train on those images, the model has never seen those images before, so having a similar accuracy is a good sign. You might think that over 90% accuracy is good, but the accuracy of this model has great room for improvement. As we move forward we will develop more accurate models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Go back to cell 10 and change the image_index once more. The model now uses the trained weight values. Nine out of ten times as we see by the accuracy it should pick the correct label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT: When you are finished make sure you go to the Jupyter notebook “File” menu above and select “Close and halt”. This will shutdown this notebook and take you back to the Jupyter Notebook Home tab.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
